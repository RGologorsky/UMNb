{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ded02a",
   "metadata": {},
   "source": [
    "# Adapted from\n",
    "\n",
    "https://github.com/Project-MONAI/tutorials/blob/main/modules/transfer_mmar.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706e3a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: monai in /home/gologors/.local/lib/python3.8/site-packages (0.8.1)\n",
      "Requirement already satisfied: torch>=1.6 in /home/gologors/.local/lib/python3.8/site-packages (from monai) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from monai) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from torch>=1.6->monai) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install monai\n",
    "# !python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, lmdb, tqdm]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, time, pickle, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# numpy to SITK conversion\n",
    "import torch\n",
    "import numpy     as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# hardware stats\n",
    "import GPUtil as GPU\n",
    "\n",
    "# plot\n",
    "from helpers.viz import viz_axis, viz_compare_inputs, viz_compare_outputs\n",
    "from helpers.viz import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MONAI\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceFocalLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import (\n",
    "    Dataset,\n",
    "    CasheDataset,\n",
    "    LMDBDataset,\n",
    "    DataLoader,\n",
    "    decollate_batch,\n",
    ")\n",
    "\n",
    "from monai.networks.utils import copy_model_state\n",
    "from monai.optimizers import generate_param_groups\n",
    "\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    CenterSpatialCropd,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    PadListDataCollate,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    SpatialPadd,\n",
    "    Orientationd,\n",
    "    CropForegroundd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandAffined,\n",
    "    RandRotated,\n",
    "    EnsureType,\n",
    "    EnsureTyped,\n",
    "    ToTensord,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac4af0",
   "metadata": {},
   "source": [
    "# Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/gologors/data/\"\n",
    "\n",
    "with open(root + 'pitmri/' + 'all_filenames_pt.pkl', 'rb') as f: \n",
    "    all_filenames = pickle.load(f)\n",
    "    \n",
    "# Split into training/valid and testing \n",
    "# adapted from https://github.com/Project-MONAI/tutorials/blob/main/modules/autoencoder_mednist.ipynb\n",
    "\n",
    "test_frac = 0.2\n",
    "valid_frac = 0.2\n",
    "\n",
    "num_test  = int(len(all_filenames) * test_frac)\n",
    "num_valid = int(len(all_filenames) * valid_frac)\n",
    "num_train = len(all_filenames) - num_test - num_valid\n",
    "\n",
    "train_datadict = [{\"im\": nii, \"lbl\":obj} for nii,obj in all_filenames[:num_train]]\n",
    "valid_datadict = [{\"im\": nii, \"lbl\":obj} for nii,obj in all_filenames[num_train:num_train+num_valid]]\n",
    "test_datadict = [{\"im\": nii, \"lbl\": obj} for nii,obj in all_filenames[-num_test:]]\n",
    "\n",
    "print(f\"total number of images: {len(all_filenames)}\")\n",
    "print(f\"number of images for training: {len(train_datadict)}\")\n",
    "print(f\"number of images for val: {len(valid_datadict)}\")\n",
    "print(f\"number of images for testing: {len(test_datadict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes\n",
    "all_shapes = []\n",
    "for im_fn, lbl_fn in all_filenames:\n",
    "    lbl_pt = torch.load(lbl_fn)\n",
    "    all_shapes.append(tuple(lbl_pt.shape))\n",
    "    print(lbl_pt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes of tensors\")\n",
    "\n",
    "print(\"Dim 0\")\n",
    "print(min(all_shapes, key=lambda s: s[0]))\n",
    "print(max(all_shapes, key=lambda s: s[0]))\n",
    "\n",
    "print(\"Dim 1\")\n",
    "print(min(all_shapes, key=lambda s: s[1]))\n",
    "print(max(all_shapes, key=lambda s: s[1]))\n",
    "\n",
    "print(\"Dim 2\")\n",
    "print(min(all_shapes, key=lambda s: s[2]))\n",
    "print(max(all_shapes, key=lambda s: s[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec71dc3",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_sz         = (576, 640, 42)\n",
    "largest_sz         = (576, 640, 96)\n",
    "center_crop_sz     = (288, 288, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75984d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pt(x):\n",
    "    d = {}\n",
    "    # do stuff to image\n",
    "    for key, val in x.items():\n",
    "        d[key] = torch.load(val)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        load_pt,\n",
    "        AddChanneld(keys=[\"im\", \"lbl\"]),\n",
    "        SpatialPadd(keys=[\"im\", \"lbl\"], spatial_size=largest_sz, method=\"symmetric\", mode=\"constant\"),\n",
    "        CenterSpatialCropd(keys=[\"im\", \"lbl\"], roi_size=center_crop_sz),\n",
    "    ]\n",
    ")\n",
    "\n",
    "valid_transforms = train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520bb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ds = Dataset(data= [{\"im\": nii, \"lbl\": obj} for nii,obj in all_filenames], transform=valid_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size=1)\n",
    "check_data = first(check_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074614f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = (check_data[\"im\"][0][0], check_data[\"lbl\"][0][0])\n",
    "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "# plot the slice [:, :, 21]\n",
    "plt.figure(\"check\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(image[:, :, center_crop_sz[2]//2], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"label\")\n",
    "plt.imshow(label[:, :, center_crop_sz[2]//2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2969b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ims = 0\n",
    "for check_data in check_loader:\n",
    "    image, label = (check_data[\"im\"][0][0], check_data[\"lbl\"][0][0])\n",
    "    print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "    # plot the slice [:, :, 21]\n",
    "    plt.figure(\"check\", (12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(image[:, :, center_crop_sz[2]//2], cmap=\"gray\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"label\")\n",
    "    plt.imshow(label[:, :, center_crop_sz[2]//2])\n",
    "    plt.show()\n",
    "    \n",
    "    count_ims += 1\n",
    "    \n",
    "    if count_ims == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2725285",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(data=train_datadict, transform=train_transforms)\n",
    "valid_ds = Dataset(data=valid_datadict, transform=valid_transforms)\n",
    "\n",
    "# train_ds = CacheDataset(data=train_datadict, transform=train_transforms, cache_rate=1.0, num_workers=2)\n",
    "# valid_ds = CacheDataset(data=valid_datadict, transform=valid_transforms, cache_rate=1.0, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05de1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=2, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c19f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED = True\n",
    "\n",
    "unet_path = f\"/home/gologors/pitmri/PituitaryGenerator/unet/model.pth\"\n",
    "checkpoint = torch.load(unet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint.keys())\n",
    "print(checkpoint[\"opt\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNET model\n",
    "model = UNet(\n",
    "                    dimensions=3,\n",
    "                    in_channels=1,\n",
    "                    out_channels=2,\n",
    "                    channels=(16, 32, 64, 128, 256),\n",
    "                    strides=(2, 2, 2, 2),\n",
    "                    num_res_units=2,\n",
    "                    dropout=0.0,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all the pretrained weights except for variables whose name matches \"model.0.conv.unit0\"\n",
    "pretrained_dict, updated_keys, unchanged_keys = copy_model_state(\n",
    "    model, checkpoint[\"model\"], exclude_vars=\"model.0.conv.unit0\")\n",
    "print(\"num. var. using the pretrained\", len(updated_keys), \", random init\", len(unchanged_keys), \"variables.\")\n",
    "model.load_state_dict(pretrained_dict)\n",
    "\n",
    "print([x[0] for x in model.named_parameters()])\n",
    "print(unchanged_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4de172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abda3f8",
   "metadata": {},
   "source": [
    "# Create an optimizer and a loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d695ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceFocalLoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "# stop gradients for the pretrained weights\n",
    "for x in model.named_parameters():\n",
    "    if x[0] in updated_keys:\n",
    "        x[1].requires_grad = False\n",
    "        \n",
    "params = generate_param_groups(\n",
    "    network=model,\n",
    "    layer_matches=[lambda x: x[0] in updated_keys],\n",
    "    match_types=[\"filter\"],\n",
    "    lr_values=[1e-4],\n",
    "    include_others=False\n",
    ")\n",
    "optimizer = torch.optim.Adam(params, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51115a3f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    \n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"im\"].to(device),\n",
    "            batch_data[\"lbl\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in DataLoader(val_ds, batch_size=1, num_workers=2):\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"im\"].to(device),\n",
    "                    val_data[\"lbl\"].to(device),\n",
    "                )\n",
    "                roi_size = (160, 160, 160)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(\n",
    "                    val_inputs, roi_size, sw_batch_size, model, overlap=0.5)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(\n",
    "                    root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )\n",
    "print(\n",
    "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "    f\"at epoch: {best_metric_epoch}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CustomEnv",
   "language": "python",
   "name": "custom_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
